{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIPS code <-> Core-based statistical area (CBSA) membership \n",
    "The user advocates asked for the ability to see what CBSA each county is in. \n",
    "This is a fairly simple exercise in merging disparate data sources. We can generalize this functionality in some powerful ways.\n",
    "- Mapping between different abstractions (spatial granularities)\n",
    "- Using LLM semantic knowledge to merge disparate data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup\n",
    "Function definitions \n",
    "TODO: separate this into a utils .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# functions for getting CBSA membership data\n",
    "tmp_save_dir = \"temporary_files\"\n",
    "\n",
    "\n",
    "def get_CBSA_geodataframe():\n",
    "    membership_df = get_CBSA_membership_df()\n",
    "    shape_df = get_CBSA_shape_df()\n",
    "    # merge, make sure it's a geodataframe, and drop rows with no membership data\n",
    "    merged_data = pd.merge(\n",
    "        shape_df, membership_df, left_on=\"CBSAFP\", right_on=\"CBSA Code\", how=\"outer\"\n",
    "    )\n",
    "    merged_data.dropna(\n",
    "        subset=[\"CBSAFP\", \"CBSA Code\", \"FIPS State Code\", \"FIPS County Code\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "    # set index to GeoFIPS\n",
    "    merged_data.set_index(\"CBSA Code\", inplace=True)\n",
    "    # fips as strings of the right length\n",
    "    merged_data[\"FIPS State Code\"] = (\n",
    "        merged_data[\"FIPS State Code\"].astype(int).astype(str).str.zfill(2)\n",
    "    )\n",
    "    merged_data[\"FIPS County Code\"] = (\n",
    "        merged_data[\"FIPS County Code\"].astype(int).astype(str).str.zfill(3)\n",
    "    )\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "def get_CBSA_membership_df():\n",
    "    # get membership data\n",
    "    membership_url = f\"https://www2.census.gov/programs-surveys/metro-micro/geographies/reference-files/2023/delineation-files/list1_2023.xlsx\"\n",
    "    response = requests.get(membership_url)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    # with open(os.path.join(tmp_save_dir, 'temp_file.xlsx'), \"wb\") as f:\n",
    "    #     f.write(response.content)\n",
    "    data = io.BytesIO(response.content)\n",
    "    membership_df = pd.read_excel(data, skiprows=2)\n",
    "    # membership_df = pd.read_excel(os.path.join(tmp_save_dir, 'temp_file.xlsx'), skiprows=2)\n",
    "    return membership_df\n",
    "\n",
    "\n",
    "def get_CBSA_shape_df():\n",
    "    # get shape data\n",
    "    YEAR = 2021  # 2021 is most recent as of Oct 28, 2023\n",
    "    URL = f\"https://www2.census.gov/geo/tiger/TIGER{YEAR}/CBSA/tl_{YEAR}_us_cbsa.zip\"\n",
    "    shape_df = gpd.read_file(URL)\n",
    "    return shape_df\n",
    "\n",
    "\n",
    "def restrict_gdf_to_county_CBSAs(geodataframe, GeoFIPS):\n",
    "    FIPS_state = GeoFIPS[:2]\n",
    "    FIPS_county = GeoFIPS[2:]\n",
    "    my_dmembership_gdf = geodataframe[\n",
    "        (geodataframe[\"FIPS State Code\"] == FIPS_state)\n",
    "        & (geodataframe[\"FIPS County Code\"] == FIPS_county)\n",
    "    ]\n",
    "    return my_membership_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Merge two datasets, one with CBSA shape files, and one with CBSA membership info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the shape data (all CBSAs)\n",
    "shape_df = get_CBSA_shape_df()\n",
    "shape_df.plot()\n",
    "display(shape_df.head())\n",
    "print(\"num of unique CBSA codes in shape data:\", len(shape_df[\"CBSAFP\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the membership data\n",
    "membership_df = get_CBSA_membership_df()\n",
    "display(membership_df.head())\n",
    "print(\n",
    "    \"num of unique CBSA codes in membership data:\",\n",
    "    len(membership_df[\"CBSA Code\"].unique()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to merge, see what's left\n",
    "merged_df = get_CBSA_geodataframe()\n",
    "merged_df.plot()\n",
    "display(merged_df.head())\n",
    "print(\"num of unique CBSA codes in merged data:\", len(merged_df.index.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Given a county FIPS code, find what CBSA(s) the county belongs to, and plot their geometry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kings county ny\n",
    "GeoFIPS = \"36047\"\n",
    "my_membership_gdf = restrict_gdf_to_county_CBSAs(merged_df, GeoFIPS)\n",
    "my_membership_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with plotly\n",
    "geodf_to_plot = my_membership_gdf.copy()\n",
    "fig = px.choropleth_mapbox(\n",
    "    geodf_to_plot,\n",
    "    geojson=geodf_to_plot.geometry,\n",
    "    locations=geodf_to_plot.index,\n",
    "    color=\"CBSA Title\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    zoom=3,\n",
    "    center={\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "    hover_data=[\"CBSA Title\", \"County/County Equivalent\", \"State Name\"],\n",
    "    opacity=0.5,\n",
    "    labels={\"CBSA Title\": \"CBSA Title\"},\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "From each CBSA, get a list of other counties in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a unique_CBSA_df df with a column for all the counties in each CBSA\n",
    "unique_CBSA_df = (\n",
    "    merged_df.groupby([\"CBSA Code\", \"CBSA Title\", \"geometry\"])[\n",
    "        \"County/County Equivalent\"\n",
    "    ]\n",
    "    .apply(lambda x: \", \".join(x))\n",
    "    .reset_index()\n",
    ")\n",
    "# convert to geodataframe\n",
    "unique_CBSA_df = gpd.GeoDataFrame(unique_CBSA_df, geometry=\"geometry\")\n",
    "# Rename columns for clarity\n",
    "unique_CBSA_df.columns = [\"CBSA Code\", \"CBSA Title\", \"geometry\", \"Counties\"]\n",
    "unique_CBSA_df.set_index(\"CBSA Code\", inplace=True)\n",
    "# # don't run too slow\n",
    "# geodf_to_plot = unique_CBSA_df.copy()\n",
    "# fig = px.choropleth_mapbox(geodf_to_plot, geojson=geodf_to_plot.geometry,\n",
    "#                            locations=geodf_to_plot.index, color='CBSA Title',\n",
    "#                            mapbox_style=\"carto-positron\",\n",
    "#                            zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "#                            hover_data=[\"CBSA Title\", \"Counties\"],\n",
    "#                            opacity=0.5,\n",
    "#                            labels={'CBSA Title':'CBSA Title'}\n",
    "#                           )\n",
    "# fig.show()\n",
    "unique_CBSA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_CBSA_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_CBSA_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Automate dataset merging using an LLM. \n",
    "\n",
    "Can an LLM use semantic knowledge to infer how to map between datasets that are formatted slightly differently? \n",
    "\n",
    "### Prompt for GPT\n",
    "I would like to merge two dataframes that have similar columns, but the columns may be named differently. Here is what they look like:\n",
    "\n",
    "```python\n",
    "dfA.head()\n",
    "CSAFP\tCBSAFP\tGEOID\tNAME\tNAMELSAD\tLSAD\tMEMI\tMTFCC\tALAND\tAWATER\tINTPTLAT\tINTPTLON\tgeometry\n",
    "0\t122\t12020\t12020\tAthens-Clarke County, GA\tAthens-Clarke County, GA Metro Area\tM1\t1\tG3110\t2654607902\t26109459\t+33.9439840\t-083.2138965\tPOLYGON ((-83.36003 34.04057, -83.36757 34.043...\n",
    "1\t122\t12060\t12060\tAtlanta-Sandy Springs-Alpharetta, GA\tAtlanta-Sandy Springs-Alpharetta, GA Metro Area\tM1\t1\tG3110\t22495873026\t386782308\t+33.6937280\t-084.3999113\tPOLYGON ((-84.27014 32.99101, -84.27084 32.991...\n",
    "2\t428\t12100\t12100\tAtlantic City-Hammonton, NJ\tAtlantic City-Hammonton, NJ Metro Area\tM1\t1\tG3110\t1438775279\t301270067\t+39.4693555\t-074.6337591\tPOLYGON ((-74.58640 39.30989, -74.58665 39.309...\n",
    "3\t426\t12120\t12120\tAtmore, AL\tAtmore, AL Micro Area\tM2\t2\tG3110\t2448595161\t20024887\t+31.1222867\t-087.1684097\tPOLYGON ((-87.36388 30.99790, -87.36391 30.997...\n",
    "4\t258\t12140\t12140\tAuburn, IN\tAuburn, IN Micro Area\tM2\t2\tG3110\t939731961\t2657419\t+41.3967596\t-085.0026969\tPOLYGON ((-85.07780 41.26560, -85.07850 41.265...\n",
    "\n",
    "CBSA Code\tMetropolitan Division Code\tCSA Code\tCBSA Title\tMetropolitan/Micropolitan Statistical Area\tMetropolitan Division Title\tCSA Title\tCounty/County Equivalent\tState Name\tFIPS State Code\tFIPS County Code\tCentral/Outlying County\n",
    "0\t10100\tNaN\tNaN\tAberdeen, SD\tMicropolitan Statistical Area\tNaN\tNaN\tBrown County\tSouth Dakota\t46.0\t13.0\tCentral\n",
    "1\t10100\tNaN\tNaN\tAberdeen, SD\tMicropolitan Statistical Area\tNaN\tNaN\tEdmunds County\tSouth Dakota\t46.0\t45.0\tOutlying\n",
    "2\t10140\tNaN\tNaN\tAberdeen, WA\tMicropolitan Statistical Area\tNaN\tNaN\tGrays Harbor County\tWashington\t53.0\t27.0\tCentral\n",
    "3\t10180\tNaN\t101.0\tAbilene, TX\tMetropolitan Statistical Area\tNaN\tAbilene-Sweetwater, TX\tCallahan County\tTexas\t48.0\t59.0\tOutlying\n",
    "4\t10180\tNaN\t101.0\tAbilene, TX\tMetropolitan Statistical Area\tNaN\tAbilene-Sweetwater, TX\tJones County\tTexas\t48.0\t253.0\tOutlying\n",
    "```\n",
    "\n",
    "\n",
    "This is the information you will share. Take your time and be careful to include as much reliable information as you can. \n",
    "```python\n",
    "merged_columns = # a list of column names for a merged df. Only include variables that you think may contained in both dataframes, just in different formats. Be careful not to include variables that are only contained in one of the dataframes -- these will be addressed separately. But if you think there's a way to convert between the dataframes and compare them, please try it. \n",
    "dict_dfA = # a dictionary of python code strings to compute the merging columns from dfA {'column1': 'dfA[\"var3\"].astype(str)', ...}\n",
    "dict_dfB = # a dictionary of python code strings to compute the merging columns from dfB {'column1': 'dfB[\"blah4\"].astype(str)', ...}\n",
    "Be very careful with your python strings to convert the data from dfA and dfB to the exact same format, so they can be merged later using pd.merge\n",
    "redundant_cols_A = # a list of redundant columns for dfA. this should include all of the columns that were used to construct dict dfB redundant_col_A = [\"var3\", ...]\n",
    "redundant_cols_B = # a list of redundant columns for dfB. this should include all of the columns that were used to construct dict dfB redundant_col_B = [\"blah4\", ...]\n",
    "cols_to_aggregate = # a dictionary. Keys are columns that should be converted to numerical values (e.g. population), and entries are aggfunc that is appropriate (e.g. sum, median, mean)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to use LLM for merge\n",
    "def LLM_assisted_merge(\n",
    "    dfA,\n",
    "    dfB,\n",
    "    merged_columns,\n",
    "    dict_dfA,\n",
    "    dict_dfB,\n",
    "    redundant_cols_A,\n",
    "    redundant_cols_B,\n",
    "    cols_to_aggregate,\n",
    "):\n",
    "    # Using the dictionaries, create new DataFrames with the desired column names\n",
    "    dfA_to_merge = dfA.copy()\n",
    "    dfB_to_merge = dfB.copy()\n",
    "\n",
    "    # Rename columns in dfA_to_merge using dict_dfA\n",
    "    for merged_col, original_col in dict_dfA.items():\n",
    "        try:\n",
    "            dfA_to_merge[merged_col] = eval(original_col)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing column {merged_col} for dfA: {e}\")\n",
    "\n",
    "    # Rename columns in dfB_to_merge using dict_dfB\n",
    "    for merged_col, original_col in dict_dfB.items():\n",
    "        try:\n",
    "            dfB_to_merge[merged_col] = eval(original_col)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing column {merged_col} for dfB: {e}\")\n",
    "\n",
    "    # Now, perform the merge on the desired columns from the merged_columns list\n",
    "    merged_df = dfA_to_merge.merge(dfB_to_merge, on=merged_columns, how=\"left\")\n",
    "\n",
    "    # Drop the redundant columns\n",
    "    merged_df.drop(columns=redundant_cols_A, inplace=True)\n",
    "    merged_df.drop(columns=redundant_cols_B, inplace=True)\n",
    "\n",
    "    # move the merged columns to the front\n",
    "    merged_df = merged_df[\n",
    "        merged_columns + [col for col in merged_df.columns if col not in merged_columns]\n",
    "    ]\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it together, with output from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### START LLM PARAMS ####\n",
    "# A list of column names for the merged dataframe. These columns will be our merging columns.\n",
    "merged_columns = [\"CSA_Code\", \"CBSA_Code\", \"Area_Type\", \"Area_Name\"]\n",
    "\n",
    "dict_dfA = {\n",
    "    \"CSA_Code\": 'dfA[\"CSAFP\"].astype(str)',\n",
    "    \"CBSA_Code\": 'dfA[\"CBSAFP\"].astype(str)',\n",
    "    \"Area_Type\": 'dfA[\"LSAD\"].map({\"M1\": \"Metropolitan\", \"M2\": \"Micropolitan\"})',\n",
    "    \"Area_Name\": 'dfA[\"NAME\"]',\n",
    "}\n",
    "\n",
    "dict_dfB = {\n",
    "    \"CSA_Code\": 'dfB[\"CSA Code\"].astype(str)',\n",
    "    \"CBSA_Code\": 'dfB[\"CBSA Code\"].astype(str)',\n",
    "    \"Area_Type\": 'dfB[\"Metropolitan/Micropolitan Statistical Area\"]',\n",
    "    \"Area_Name\": 'dfB[\"CBSA Title\"]',\n",
    "}\n",
    "\n",
    "redundant_cols_A = [\"CSAFP\", \"CBSAFP\", \"LSAD\", \"NAME\", \"NAMELSAD\"]\n",
    "\n",
    "redundant_cols_B = [\n",
    "    \"CSA Code\",\n",
    "    \"CBSA Code\",\n",
    "    \"Metropolitan/Micropolitan Statistical Area\",\n",
    "    \"CBSA Title\",\n",
    "    \"Metropolitan Division Code\",\n",
    "    \"CSA Title\",\n",
    "    \"Metropolitan Division Title\",\n",
    "]\n",
    "\n",
    "cols_to_aggregate = {\"ALAND\": \"sum\", \"AWATER\": \"sum\"}\n",
    "\n",
    "#### END LLM PARAMS ####\n",
    "\n",
    "# using LLM params for merge\n",
    "dfA = shape_df\n",
    "dfB = membership_df\n",
    "\n",
    "merged_df = LLM_assisted_merge(\n",
    "    dfA,\n",
    "    dfB,\n",
    "    merged_columns,\n",
    "    dict_dfA,\n",
    "    dict_dfB,\n",
    "    redundant_cols_A,\n",
    "    redundant_cols_B,\n",
    "    cols_to_aggregate,\n",
    ")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Aggregate/dissolve/abstract the merged dataset by different variables. There's not always one canonical way to do it -- the columns give us options for possible relevant abstractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 'first' aggregation method if not specified by LLM\n",
    "for col in merged_df.columns:\n",
    "    if col not in cols_to_aggregate:\n",
    "        # not geometry either\n",
    "        if col != \"geometry\":\n",
    "            cols_to_aggregate[col] = \"first\"\n",
    "\n",
    "# try different abstractions\n",
    "for col in cols_to_aggregate:\n",
    "    print(\"Try aggregating by\", col)\n",
    "    dissolve_by = col\n",
    "    dissolve_me = merged_df.copy().dropna(subset=[dissolve_by])\n",
    "    dissolved = dissolve_me.dissolve(\n",
    "        by=dissolve_by, aggfunc=cols_to_aggregate\n",
    "    )  # in the future, can set aggfunc to median, mean, etc.\n",
    "    # if nonempty, plot\n",
    "    if not dissolved.empty:\n",
    "        ax = dissolved.plot(column=dissolve_by)\n",
    "        ax.set_title(\"Aggregated by \" + dissolve_by)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
