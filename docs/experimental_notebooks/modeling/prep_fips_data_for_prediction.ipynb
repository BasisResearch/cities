{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from cities.utils.data_grabber import (\n",
    "    DataGrabber,\n",
    "    list_available_features,\n",
    "    list_tensed_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fips_data_for_prediction(\n",
    "    fips, outcome_dataset, intervention_dataset, forward_shift\n",
    "):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    dg = DataGrabber()\n",
    "\n",
    "    tensed_covariates_datasets = [\n",
    "        var\n",
    "        for var in list_tensed_features()\n",
    "        if var not in [outcome_dataset, intervention_dataset]\n",
    "    ]\n",
    "    fixed_covariates_datasets = [\n",
    "        var\n",
    "        for var in list_available_features()\n",
    "        if var\n",
    "        not in tensed_covariates_datasets + [outcome_dataset, intervention_dataset]\n",
    "    ]\n",
    "\n",
    "    features_needed = [\n",
    "        outcome_dataset,\n",
    "        intervention_dataset,\n",
    "    ] + fixed_covariates_datasets\n",
    "\n",
    "    dg.get_features_std_wide(features_needed)\n",
    "\n",
    "    intervention = dg.std_wide[intervention_dataset][\n",
    "        dg.std_wide[intervention_dataset][\"GeoFIPS\"] == fips\n",
    "    ].copy()\n",
    "    outcome = dg.std_wide[outcome_dataset][\n",
    "        dg.std_wide[outcome_dataset][\"GeoFIPS\"] == fips\n",
    "    ].copy()\n",
    "\n",
    "    # put covariates in one df as columns, dropping repeated ID columns\n",
    "    f_covariates = {\n",
    "        dataset: dg.std_wide[dataset] for dataset in fixed_covariates_datasets\n",
    "    }\n",
    "    f_covariates_joint = f_covariates[fixed_covariates_datasets[0]]\n",
    "    for dataset in f_covariates.keys():\n",
    "        if dataset != fixed_covariates_datasets[0]:\n",
    "            if \"GeoName\" in f_covariates[dataset].columns:\n",
    "                f_covariates[dataset] = f_covariates[dataset].drop(columns=[\"GeoName\"])\n",
    "            f_covariates_joint = f_covariates_joint.merge(\n",
    "                f_covariates[dataset], on=[\"GeoFIPS\"]\n",
    "            )\n",
    "\n",
    "    # extract data for which intervention and outcome overlap\n",
    "    year_min = max(\n",
    "        intervention.columns[2:].astype(int).min(),\n",
    "        outcome.columns[2:].astype(int).min(),\n",
    "    )\n",
    "\n",
    "    year_max = min(\n",
    "        intervention.columns[2:].astype(int).max(),\n",
    "        outcome.columns[2:].astype(int).max(),\n",
    "    )\n",
    "\n",
    "    assert all(intervention[\"GeoFIPS\"] == outcome[\"GeoFIPS\"])\n",
    "\n",
    "    outcome_years_to_keep = [\n",
    "        year\n",
    "        for year in outcome.columns[2:]\n",
    "        if year_min <= int(year) <= year_max + forward_shift\n",
    "    ]\n",
    "\n",
    "    outcome_years_to_keep = [\n",
    "        year for year in outcome_years_to_keep if year in intervention.columns[2:]\n",
    "    ]\n",
    "\n",
    "    outcome = outcome[outcome_years_to_keep]\n",
    "\n",
    "    # shift outcome `forward_shift` steps ahead\n",
    "    # for the prediction task\n",
    "    outcome_shifted = outcome.copy()\n",
    "\n",
    "    for i in range(len(outcome_years_to_keep) - forward_shift):\n",
    "        outcome_shifted.iloc[:, i] = outcome_shifted.iloc[:, i + forward_shift]\n",
    "\n",
    "    years_to_drop = [\n",
    "        f\"{year}\" for year in range(year_max - forward_shift + 1, year_max + 1)\n",
    "    ]\n",
    "    outcome_shifted.drop(columns=years_to_drop, inplace=True)\n",
    "\n",
    "    intervention.drop(columns=[\"GeoFIPS\", \"GeoName\"], inplace=True)\n",
    "    intervention = intervention[outcome_shifted.columns]\n",
    "\n",
    "    assert intervention.shape == outcome_shifted.shape\n",
    "\n",
    "    unit_index = pd.factorize(f_covariates_joint[\"GeoFIPS\"].values)[0]\n",
    "    unit_index = unit_index[f_covariates_joint[\"GeoFIPS\"] == fips]\n",
    "\n",
    "    state_index = pd.factorize(f_covariates_joint[\"GeoFIPS\"].values // 1000)[0]\n",
    "    state_index = state_index[f_covariates_joint[\"GeoFIPS\"] == fips]\n",
    "\n",
    "    f_covariates_joint = f_covariates_joint[f_covariates_joint[\"GeoFIPS\"] == fips]\n",
    "\n",
    "    # prepare tensors\n",
    "    x = torch.tensor(\n",
    "        f_covariates_joint.iloc[:, 2:].values, dtype=torch.float32, device=device\n",
    "    )\n",
    "    x = x.unsqueeze(1).unsqueeze(1).permute(2, 3, 1, 0)\n",
    "\n",
    "    t = torch.tensor(intervention.values, dtype=torch.float32, device=device)\n",
    "    t = t.unsqueeze(1).unsqueeze(1).permute(3, 1, 2, 0)\n",
    "\n",
    "    y = torch.tensor(outcome_shifted.values, dtype=torch.float32, device=device)\n",
    "    y = y.unsqueeze(1).unsqueeze(1).permute(3, 1, 2, 0)\n",
    "\n",
    "    state_index = torch.tensor(state_index, dtype=torch.int, device=device)\n",
    "    unit_index = torch.tensor(unit_index, dtype=torch.int, device=device)\n",
    "\n",
    "    N_t = y.shape[0]\n",
    "    N_cov = x.shape[1]\n",
    "    N_s = state_index.unique().shape[0]\n",
    "    N_u = unit_index.unique().shape[0]\n",
    "\n",
    "    assert x.shape == (1, N_cov, 1, N_u)\n",
    "    assert y.shape == (N_t, 1, 1, N_u)\n",
    "    assert t.shape == (N_t, 1, 1, N_u)\n",
    "\n",
    "    model_args = (N_t, N_cov, N_s, N_u, state_index, unit_index)\n",
    "\n",
    "    return {\"model_args\": model_args, \"x\": x, \"t\": t, \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fips = prep_fips_data_for_prediction(1003, \"gdp\", \"spending_commerce\", 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chirho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
